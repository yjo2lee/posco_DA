{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stand_price</th>\n",
       "      <th>fluc_price</th>\n",
       "      <th>fluc_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-02-02</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-03-02</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-03-30</td>\n",
       "      <td>17.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-05-04</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  stand_price  fluc_price  fluc_rate\n",
       "0  2001-02-02        17.36        0.00       0.00\n",
       "1  2001-03-02        17.36        0.00       0.00\n",
       "2  2001-03-30        17.36        0.00       0.00\n",
       "3  2001-05-04        18.10        0.74       4.26\n",
       "4  2001-06-01        18.10        0.00       0.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"data/posco1.csv\")   #read data\n",
    "raw_df.columns = ['date', 'stand_price', 'fluc_price', 'fluc_rate']\n",
    "col_total = len(raw_df['date'])   # length of column\n",
    "raw_df.head()\n",
    "df = raw_df   # change dataframe with all variables\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(col_total): \n",
    "    #print(raw_df.values[i,0][0:4])\n",
    "    df.loc[i,'year'] = int(raw_df.values[i,0][0:4])\n",
    "    df.loc[i,'month'] = raw_df.values[i,0][5:7]\n",
    "    df.loc[i,'day'] = raw_df.values[i,0][8:10]\n",
    "df.head()\n",
    "\n",
    "# Data slicing\n",
    "sub_df_09 = df.loc[df.year>2008, :]\n",
    "Dataxy = np.array(sub_df_09.stand_price)\n",
    "sample_size = len(Dataxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "input_size = 1\n",
    "num_steps = 15\n",
    "hidden_size = 5\n",
    "lstm_size = 128\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "iterations = 500\n",
    "num_layers = 2\n",
    "\n",
    "# Data preparation\n",
    "seq = MinMaxScaler(Dataxy)   # Normalization: unless being out of scale?\n",
    "#seq = Dataxy\n",
    "seq = [np.array(seq[i * input_size: (i + 1) * input_size]) \n",
    "       for i in range(len(seq) // input_size)]\n",
    "\n",
    "# Split into groups of `num_steps`\n",
    "dataX = np.array([seq[i: i + num_steps] for i in range(len(seq) - num_steps)])\n",
    "dataY = np.array([seq[i + num_steps] for i in range(len(seq) - num_steps)])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# train/test split: take the latest 10% of data as the test data\n",
    "train_size = int(len(dataY) * 0.9)\n",
    "#valid_size = train_size - int(train_size*0.9)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(\n",
    "    dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(\n",
    "    dataY[train_size:len(dataY)])\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, num_steps, input_size])\n",
    "Y = tf.placeholder(tf.float32, [None, input_size])\n",
    "\n",
    "# input_size =   #sliding window of a fixed size, use w(t) to predict w(t-1)\n",
    "### there is no overlap between two consecutive windows\n",
    "### input_size 만큼의 데이터가 w(t)안에 포함\n",
    "# num_steps =2 means [w(t), w(t+1)] -> w(t+2)\n",
    "#print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 110.24334716796875\n",
      "[step: 1] loss: 223.84767150878906\n",
      "[step: 2] loss: 192.68385314941406\n",
      "[step: 3] loss: 106.64203643798828\n",
      "[step: 4] loss: 62.71196746826172\n",
      "[step: 5] loss: 15.720846176147461\n",
      "[step: 6] loss: 115.11505126953125\n",
      "[step: 7] loss: 13.651721954345703\n",
      "[step: 8] loss: 43.591835021972656\n",
      "[step: 9] loss: 58.69857406616211\n",
      "[step: 10] loss: 59.60820770263672\n",
      "[step: 11] loss: 51.75442886352539\n",
      "[step: 12] loss: 38.55780029296875\n",
      "[step: 13] loss: 23.302488327026367\n",
      "[step: 14] loss: 13.598759651184082\n",
      "[step: 15] loss: 24.167165756225586\n",
      "[step: 16] loss: 29.397428512573242\n",
      "[step: 17] loss: 16.91421890258789\n",
      "[step: 18] loss: 12.682475090026855\n",
      "[step: 19] loss: 14.857718467712402\n",
      "[step: 20] loss: 17.351219177246094\n",
      "[step: 21] loss: 17.63351821899414\n",
      "[step: 22] loss: 15.301581382751465\n",
      "[step: 23] loss: 11.188130378723145\n",
      "[step: 24] loss: 7.272862434387207\n",
      "[step: 25] loss: 6.271735668182373\n",
      "[step: 26] loss: 8.538690567016602\n",
      "[step: 27] loss: 8.506352424621582\n",
      "[step: 28] loss: 4.555356025695801\n",
      "[step: 29] loss: 2.9648325443267822\n",
      "[step: 30] loss: 5.034824371337891\n",
      "[step: 31] loss: 7.0612406730651855\n",
      "[step: 32] loss: 6.44219446182251\n",
      "[step: 33] loss: 4.245258808135986\n",
      "[step: 34] loss: 3.3971774578094482\n",
      "[step: 35] loss: 4.451301097869873\n",
      "[step: 36] loss: 4.689852714538574\n",
      "[step: 37] loss: 3.4560813903808594\n",
      "[step: 38] loss: 2.7252509593963623\n",
      "[step: 39] loss: 3.0843241214752197\n",
      "[step: 40] loss: 3.743983745574951\n",
      "[step: 41] loss: 4.001519203186035\n",
      "[step: 42] loss: 3.7137441635131836\n",
      "[step: 43] loss: 3.183891534805298\n",
      "[step: 44] loss: 2.8693010807037354\n",
      "[step: 45] loss: 2.9823410511016846\n",
      "[step: 46] loss: 3.2193567752838135\n",
      "[step: 47] loss: 3.1044087409973145\n",
      "[step: 48] loss: 2.6806395053863525\n",
      "[step: 49] loss: 2.4146432876586914\n",
      "[step: 50] loss: 2.502474308013916\n",
      "[step: 51] loss: 2.711186647415161\n",
      "[step: 52] loss: 2.750753164291382\n",
      "[step: 53] loss: 2.5836689472198486\n",
      "[step: 54] loss: 2.4196889400482178\n",
      "[step: 55] loss: 2.4425127506256104\n",
      "[step: 56] loss: 2.551630973815918\n",
      "[step: 57] loss: 2.512434482574463\n",
      "[step: 58] loss: 2.336169481277466\n",
      "[step: 59] loss: 2.2296180725097656\n",
      "[step: 60] loss: 2.261549472808838\n",
      "[step: 61] loss: 2.3203368186950684\n",
      "[step: 62] loss: 2.302145481109619\n",
      "[step: 63] loss: 2.2237613201141357\n",
      "[step: 64] loss: 2.17525315284729\n",
      "[step: 65] loss: 2.197214126586914\n",
      "[step: 66] loss: 2.227908134460449\n",
      "[step: 67] loss: 2.1959376335144043\n",
      "[step: 68] loss: 2.12516450881958\n",
      "[step: 69] loss: 2.0873236656188965\n",
      "[step: 70] loss: 2.094388246536255\n",
      "[step: 71] loss: 2.097269296646118\n",
      "[step: 72] loss: 2.0647642612457275\n",
      "[step: 73] loss: 2.023045301437378\n",
      "[step: 74] loss: 2.0120677947998047\n",
      "[step: 75] loss: 2.0239017009735107\n",
      "[step: 76] loss: 2.0167715549468994\n",
      "[step: 77] loss: 1.9841467142105103\n",
      "[step: 78] loss: 1.959457278251648\n",
      "[step: 79] loss: 1.9556797742843628\n",
      "[step: 80] loss: 1.9500598907470703\n",
      "[step: 81] loss: 1.9268070459365845\n",
      "[step: 82] loss: 1.9004509449005127\n",
      "[step: 83] loss: 1.889326810836792\n",
      "[step: 84] loss: 1.886312484741211\n",
      "[step: 85] loss: 1.8736506700515747\n",
      "[step: 86] loss: 1.8533883094787598\n",
      "[step: 87] loss: 1.8400415182113647\n",
      "[step: 88] loss: 1.8339349031448364\n",
      "[step: 89] loss: 1.8230278491973877\n",
      "[step: 90] loss: 1.8045097589492798\n",
      "[step: 91] loss: 1.7880902290344238\n",
      "[step: 92] loss: 1.77839195728302\n",
      "[step: 93] loss: 1.7680621147155762\n",
      "[step: 94] loss: 1.7526299953460693\n",
      "[step: 95] loss: 1.7382307052612305\n",
      "[step: 96] loss: 1.7288284301757812\n",
      "[step: 97] loss: 1.7191977500915527\n",
      "[step: 98] loss: 1.7054938077926636\n",
      "[step: 99] loss: 1.6917394399642944\n",
      "[step: 100] loss: 1.6812183856964111\n",
      "[step: 101] loss: 1.6705517768859863\n",
      "[step: 102] loss: 1.65729558467865\n",
      "[step: 103] loss: 1.6446985006332397\n",
      "[step: 104] loss: 1.634642481803894\n",
      "[step: 105] loss: 1.6242671012878418\n",
      "[step: 106] loss: 1.6122076511383057\n",
      "[step: 107] loss: 1.6009039878845215\n",
      "[step: 108] loss: 1.5911349058151245\n",
      "[step: 109] loss: 1.5806777477264404\n",
      "[step: 110] loss: 1.569279432296753\n",
      "[step: 111] loss: 1.5589009523391724\n",
      "[step: 112] loss: 1.549350380897522\n",
      "[step: 113] loss: 1.5390565395355225\n",
      "[step: 114] loss: 1.5286158323287964\n",
      "[step: 115] loss: 1.5192548036575317\n",
      "[step: 116] loss: 1.510145664215088\n",
      "[step: 117] loss: 1.500531554222107\n",
      "[step: 118] loss: 1.4913594722747803\n",
      "[step: 119] loss: 1.4828550815582275\n",
      "[step: 120] loss: 1.4740824699401855\n",
      "[step: 121] loss: 1.4652245044708252\n",
      "[step: 122] loss: 1.4570339918136597\n",
      "[step: 123] loss: 1.4490859508514404\n",
      "[step: 124] loss: 1.4410061836242676\n",
      "[step: 125] loss: 1.4333521127700806\n",
      "[step: 126] loss: 1.42610764503479\n",
      "[step: 127] loss: 1.4187544584274292\n",
      "[step: 128] loss: 1.4115511178970337\n",
      "[step: 129] loss: 1.4047743082046509\n",
      "[step: 130] loss: 1.398058533668518\n",
      "[step: 131] loss: 1.39141845703125\n",
      "[step: 132] loss: 1.3851540088653564\n",
      "[step: 133] loss: 1.3790366649627686\n",
      "[step: 134] loss: 1.3729432821273804\n",
      "[step: 135] loss: 1.3671237230300903\n",
      "[step: 136] loss: 1.3614780902862549\n",
      "[step: 137] loss: 1.3558483123779297\n",
      "[step: 138] loss: 1.3504095077514648\n",
      "[step: 139] loss: 1.3451305627822876\n",
      "[step: 140] loss: 1.3398655652999878\n",
      "[step: 141] loss: 1.3347382545471191\n",
      "[step: 142] loss: 1.3297510147094727\n",
      "[step: 143] loss: 1.324776530265808\n",
      "[step: 144] loss: 1.3198890686035156\n",
      "[step: 145] loss: 1.3150972127914429\n",
      "[step: 146] loss: 1.3103044033050537\n",
      "[step: 147] loss: 1.3055648803710938\n",
      "[step: 148] loss: 1.3008943796157837\n",
      "[step: 149] loss: 1.2962183952331543\n",
      "[step: 150] loss: 1.2915760278701782\n",
      "[step: 151] loss: 1.2869764566421509\n",
      "[step: 152] loss: 1.2823635339736938\n",
      "[step: 153] loss: 1.2777669429779053\n",
      "[step: 154] loss: 1.2731915712356567\n",
      "[step: 155] loss: 1.2685974836349487\n",
      "[step: 156] loss: 1.264009714126587\n",
      "[step: 157] loss: 1.2594327926635742\n",
      "[step: 158] loss: 1.2548404932022095\n",
      "[step: 159] loss: 1.2502509355545044\n",
      "[step: 160] loss: 1.2456647157669067\n",
      "[step: 161] loss: 1.2410615682601929\n",
      "[step: 162] loss: 1.236457347869873\n",
      "[step: 163] loss: 1.2318525314331055\n",
      "[step: 164] loss: 1.2272348403930664\n",
      "[step: 165] loss: 1.2226178646087646\n",
      "[step: 166] loss: 1.21799898147583\n",
      "[step: 167] loss: 1.213369369506836\n",
      "[step: 168] loss: 1.2087393999099731\n",
      "[step: 169] loss: 1.204107403755188\n",
      "[step: 170] loss: 1.1994680166244507\n",
      "[step: 171] loss: 1.1948292255401611\n",
      "[step: 172] loss: 1.1901873350143433\n",
      "[step: 173] loss: 1.1855404376983643\n",
      "[step: 174] loss: 1.1808936595916748\n",
      "[step: 175] loss: 1.1762458086013794\n",
      "[step: 176] loss: 1.1715948581695557\n",
      "[step: 177] loss: 1.1669450998306274\n",
      "[step: 178] loss: 1.1622931957244873\n",
      "[step: 179] loss: 1.1576392650604248\n",
      "[step: 180] loss: 1.15298593044281\n",
      "[step: 181] loss: 1.1483319997787476\n",
      "[step: 182] loss: 1.1436777114868164\n",
      "[step: 183] loss: 1.1390247344970703\n",
      "[step: 184] loss: 1.1343708038330078\n",
      "[step: 185] loss: 1.1297167539596558\n",
      "[step: 186] loss: 1.125064492225647\n",
      "[step: 187] loss: 1.1204122304916382\n",
      "[step: 188] loss: 1.115761637687683\n",
      "[step: 189] loss: 1.1111127138137817\n",
      "[step: 190] loss: 1.1064647436141968\n",
      "[step: 191] loss: 1.1018187999725342\n",
      "[step: 192] loss: 1.0971755981445312\n",
      "[step: 193] loss: 1.092535138130188\n",
      "[step: 194] loss: 1.0878978967666626\n",
      "[step: 195] loss: 1.0832643508911133\n",
      "[step: 196] loss: 1.078634262084961\n",
      "[step: 197] loss: 1.0740092992782593\n",
      "[step: 198] loss: 1.0693893432617188\n",
      "[step: 199] loss: 1.0647753477096558\n",
      "[step: 200] loss: 1.060167670249939\n",
      "[step: 201] loss: 1.0555669069290161\n",
      "[step: 202] loss: 1.0509735345840454\n",
      "[step: 203] loss: 1.0463885068893433\n",
      "[step: 204] loss: 1.0418131351470947\n",
      "[step: 205] loss: 1.0372475385665894\n",
      "[step: 206] loss: 1.0326926708221436\n",
      "[step: 207] loss: 1.0281493663787842\n",
      "[step: 208] loss: 1.0236188173294067\n",
      "[step: 209] loss: 1.019101858139038\n",
      "[step: 210] loss: 1.014599323272705\n",
      "[step: 211] loss: 1.0101125240325928\n",
      "[step: 212] loss: 1.0056419372558594\n",
      "[step: 213] loss: 1.00118887424469\n",
      "[step: 214] loss: 0.9967548251152039\n",
      "[step: 215] loss: 0.9923399686813354\n",
      "[step: 216] loss: 0.9879461526870728\n",
      "[step: 217] loss: 0.9835739731788635\n",
      "[step: 218] loss: 0.9792245626449585\n",
      "[step: 219] loss: 0.974899172782898\n",
      "[step: 220] loss: 0.9705986380577087\n",
      "[step: 221] loss: 0.9663240313529968\n",
      "[step: 222] loss: 0.9620762467384338\n",
      "[step: 223] loss: 0.9578559398651123\n",
      "[step: 224] loss: 0.9536644816398621\n",
      "[step: 225] loss: 0.9495021104812622\n",
      "[step: 226] loss: 0.945370078086853\n",
      "[step: 227] loss: 0.9412685632705688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 228] loss: 0.9371980428695679\n",
      "[step: 229] loss: 0.9331591129302979\n",
      "[step: 230] loss: 0.9291520714759827\n",
      "[step: 231] loss: 0.9251768589019775\n",
      "[step: 232] loss: 0.9212334752082825\n",
      "[step: 233] loss: 0.9173216819763184\n",
      "[step: 234] loss: 0.9134417772293091\n",
      "[step: 235] loss: 0.9095925092697144\n",
      "[step: 236] loss: 0.9057737588882446\n",
      "[step: 237] loss: 0.9019843339920044\n",
      "[step: 238] loss: 0.8982234001159668\n",
      "[step: 239] loss: 0.8944900035858154\n",
      "[step: 240] loss: 0.8907824158668518\n",
      "[step: 241] loss: 0.8870992660522461\n",
      "[step: 242] loss: 0.8834390044212341\n",
      "[step: 243] loss: 0.8797997236251831\n",
      "[step: 244] loss: 0.8761797547340393\n",
      "[step: 245] loss: 0.8725763559341431\n",
      "[step: 246] loss: 0.8689879775047302\n",
      "[step: 247] loss: 0.8654120564460754\n",
      "[step: 248] loss: 0.8618463277816772\n",
      "[step: 249] loss: 0.8582881689071655\n",
      "[step: 250] loss: 0.8547354340553284\n",
      "[step: 251] loss: 0.8511855602264404\n",
      "[step: 252] loss: 0.8476360440254211\n",
      "[step: 253] loss: 0.8440843224525452\n",
      "[step: 254] loss: 0.8405278921127319\n",
      "[step: 255] loss: 0.8369647860527039\n",
      "[step: 256] loss: 0.8333924412727356\n",
      "[step: 257] loss: 0.8298086524009705\n",
      "[step: 258] loss: 0.8262112736701965\n",
      "[step: 259] loss: 0.8225985169410706\n",
      "[step: 260] loss: 0.8189677596092224\n",
      "[step: 261] loss: 0.8153182864189148\n",
      "[step: 262] loss: 0.8116467595100403\n",
      "[step: 263] loss: 0.8079527616500854\n",
      "[step: 264] loss: 0.8042343258857727\n",
      "[step: 265] loss: 0.8004896640777588\n",
      "[step: 266] loss: 0.796717643737793\n",
      "[step: 267] loss: 0.7929167151451111\n",
      "[step: 268] loss: 0.7890856862068176\n",
      "[step: 269] loss: 0.7852229475975037\n",
      "[step: 270] loss: 0.7813275456428528\n",
      "[step: 271] loss: 0.7773981094360352\n",
      "[step: 272] loss: 0.7734333872795105\n",
      "[step: 273] loss: 0.7694317698478699\n",
      "[step: 274] loss: 0.7653926014900208\n",
      "[step: 275] loss: 0.7613138556480408\n",
      "[step: 276] loss: 0.7571949362754822\n",
      "[step: 277] loss: 0.7530339360237122\n",
      "[step: 278] loss: 0.7488295435905457\n",
      "[step: 279] loss: 0.7445802688598633\n",
      "[step: 280] loss: 0.7402843236923218\n",
      "[step: 281] loss: 0.735940158367157\n",
      "[step: 282] loss: 0.7315462827682495\n",
      "[step: 283] loss: 0.7271004915237427\n",
      "[step: 284] loss: 0.7226006388664246\n",
      "[step: 285] loss: 0.7180452942848206\n",
      "[step: 286] loss: 0.7134320735931396\n",
      "[step: 287] loss: 0.7087585926055908\n",
      "[step: 288] loss: 0.7040228247642517\n",
      "[step: 289] loss: 0.6992219686508179\n",
      "[step: 290] loss: 0.6943536996841431\n",
      "[step: 291] loss: 0.6894159317016602\n",
      "[step: 292] loss: 0.6844049096107483\n",
      "[step: 293] loss: 0.6793192625045776\n",
      "[step: 294] loss: 0.6741551756858826\n",
      "[step: 295] loss: 0.6689341068267822\n",
      "[step: 296] loss: 0.6638354659080505\n",
      "[step: 297] loss: 0.6614602208137512\n",
      "[step: 298] loss: 0.6992737054824829\n",
      "[step: 299] loss: 1.4037443399429321\n",
      "[step: 300] loss: 11.9434814453125\n",
      "[step: 301] loss: 40.61447525024414\n",
      "[step: 302] loss: 7.2816996574401855\n",
      "[step: 303] loss: 2.0924675464630127\n",
      "[step: 304] loss: 3.2764554023742676\n",
      "[step: 305] loss: 3.719184160232544\n",
      "[step: 306] loss: 2.0806572437286377\n",
      "[step: 307] loss: 2.2871601581573486\n",
      "[step: 308] loss: 3.059730291366577\n",
      "[step: 309] loss: 1.661103367805481\n",
      "[step: 310] loss: 1.7882431745529175\n",
      "[step: 311] loss: 3.0687384605407715\n",
      "[step: 312] loss: 1.4944578409194946\n",
      "[step: 313] loss: 2.1837656497955322\n",
      "[step: 314] loss: 1.9412771463394165\n",
      "[step: 315] loss: 1.1337823867797852\n",
      "[step: 316] loss: 1.7548481225967407\n",
      "[step: 317] loss: 1.8760415315628052\n",
      "[step: 318] loss: 1.3774116039276123\n",
      "[step: 319] loss: 1.6041542291641235\n",
      "[step: 320] loss: 1.7087815999984741\n",
      "[step: 321] loss: 1.2479922771453857\n",
      "[step: 322] loss: 1.1317452192306519\n",
      "[step: 323] loss: 1.396889090538025\n",
      "[step: 324] loss: 1.1784614324569702\n",
      "[step: 325] loss: 1.119773268699646\n",
      "[step: 326] loss: 1.3478294610977173\n",
      "[step: 327] loss: 1.2141841650009155\n",
      "[step: 328] loss: 1.032589316368103\n",
      "[step: 329] loss: 1.1429647207260132\n",
      "[step: 330] loss: 1.093390941619873\n",
      "[step: 331] loss: 0.9638437032699585\n",
      "[step: 332] loss: 1.0457700490951538\n",
      "[step: 333] loss: 1.091425895690918\n",
      "[step: 334] loss: 0.99894118309021\n",
      "[step: 335] loss: 0.9849115014076233\n",
      "[step: 336] loss: 1.0318652391433716\n",
      "[step: 337] loss: 0.9646925330162048\n",
      "[step: 338] loss: 0.9111587405204773\n",
      "[step: 339] loss: 0.9513450860977173\n",
      "[step: 340] loss: 0.9435071349143982\n",
      "[step: 341] loss: 0.8989971876144409\n",
      "[step: 342] loss: 0.923630952835083\n",
      "[step: 343] loss: 0.9340019226074219\n",
      "[step: 344] loss: 0.888746976852417\n",
      "[step: 345] loss: 0.8849632143974304\n",
      "[step: 346] loss: 0.8946904540061951\n",
      "[step: 347] loss: 0.866478443145752\n",
      "[step: 348] loss: 0.8558831214904785\n",
      "[step: 349] loss: 0.8722421526908875\n",
      "[step: 350] loss: 0.86175137758255\n",
      "[step: 351] loss: 0.8460742235183716\n",
      "[step: 352] loss: 0.8526389002799988\n",
      "[step: 353] loss: 0.8477240800857544\n",
      "[step: 354] loss: 0.8293592929840088\n",
      "[step: 355] loss: 0.828029215335846\n",
      "[step: 356] loss: 0.8295634984970093\n",
      "[step: 357] loss: 0.8179660439491272\n",
      "[step: 358] loss: 0.8148564100265503\n",
      "[step: 359] loss: 0.8180479407310486\n",
      "[step: 360] loss: 0.8100467324256897\n",
      "[step: 361] loss: 0.8027245998382568\n",
      "[step: 362] loss: 0.8030329346656799\n",
      "[step: 363] loss: 0.797537624835968\n",
      "[step: 364] loss: 0.7901549339294434\n",
      "[step: 365] loss: 0.7897477746009827\n",
      "[step: 366] loss: 0.7876742482185364\n",
      "[step: 367] loss: 0.7817590236663818\n",
      "[step: 368] loss: 0.7796223759651184\n",
      "[step: 369] loss: 0.7778946757316589\n",
      "[step: 370] loss: 0.7723292708396912\n",
      "[step: 371] loss: 0.7686266303062439\n",
      "[step: 372] loss: 0.7670419812202454\n",
      "[step: 373] loss: 0.7630976438522339\n",
      "[step: 374] loss: 0.7594757080078125\n",
      "[step: 375] loss: 0.7579873204231262\n",
      "[step: 376] loss: 0.7549756169319153\n",
      "[step: 377] loss: 0.7511175870895386\n",
      "[step: 378] loss: 0.7488480806350708\n",
      "[step: 379] loss: 0.7460894584655762\n",
      "[step: 380] loss: 0.7424246668815613\n",
      "[step: 381] loss: 0.739970326423645\n",
      "[step: 382] loss: 0.7377179265022278\n",
      "[step: 383] loss: 0.7345521450042725\n",
      "[step: 384] loss: 0.7319247126579285\n",
      "[step: 385] loss: 0.7296590805053711\n",
      "[step: 386] loss: 0.7266459465026855\n",
      "[step: 387] loss: 0.7237970232963562\n",
      "[step: 388] loss: 0.7214718461036682\n",
      "[step: 389] loss: 0.718751847743988\n",
      "[step: 390] loss: 0.7160200476646423\n",
      "[step: 391] loss: 0.7137368321418762\n",
      "[step: 392] loss: 0.7112030982971191\n",
      "[step: 393] loss: 0.7084839940071106\n",
      "[step: 394] loss: 0.7060802578926086\n",
      "[step: 395] loss: 0.7035895586013794\n",
      "[step: 396] loss: 0.700933575630188\n",
      "[step: 397] loss: 0.6985325813293457\n",
      "[step: 398] loss: 0.6961506009101868\n",
      "[step: 399] loss: 0.6936075091362\n",
      "[step: 400] loss: 0.6912049055099487\n",
      "[step: 401] loss: 0.6888394355773926\n",
      "[step: 402] loss: 0.6863362789154053\n",
      "[step: 403] loss: 0.6839224100112915\n",
      "[step: 404] loss: 0.68157559633255\n",
      "[step: 405] loss: 0.6791359782218933\n",
      "[step: 406] loss: 0.6767510175704956\n",
      "[step: 407] loss: 0.6744307279586792\n",
      "[step: 408] loss: 0.6720397472381592\n",
      "[step: 409] loss: 0.6696723699569702\n",
      "[step: 410] loss: 0.6673541069030762\n",
      "[step: 411] loss: 0.6649832725524902\n",
      "[step: 412] loss: 0.6626277565956116\n",
      "[step: 413] loss: 0.6603204607963562\n",
      "[step: 414] loss: 0.6579833030700684\n",
      "[step: 415] loss: 0.655656635761261\n",
      "[step: 416] loss: 0.6533620953559875\n",
      "[step: 417] loss: 0.6510376930236816\n",
      "[step: 418] loss: 0.6487155556678772\n",
      "[step: 419] loss: 0.6464194059371948\n",
      "[step: 420] loss: 0.6441073417663574\n",
      "[step: 421] loss: 0.6418037414550781\n",
      "[step: 422] loss: 0.6395193338394165\n",
      "[step: 423] loss: 0.6372190117835999\n",
      "[step: 424] loss: 0.6349223256111145\n",
      "[step: 425] loss: 0.6326382160186768\n",
      "[step: 426] loss: 0.6303439736366272\n",
      "[step: 427] loss: 0.6280573010444641\n",
      "[step: 428] loss: 0.625779390335083\n",
      "[step: 429] loss: 0.6234927177429199\n",
      "[step: 430] loss: 0.6212126612663269\n",
      "[step: 431] loss: 0.6189377903938293\n",
      "[step: 432] loss: 0.6166584491729736\n",
      "[step: 433] loss: 0.6143863201141357\n",
      "[step: 434] loss: 0.6121158003807068\n",
      "[step: 435] loss: 0.6098414659500122\n",
      "[step: 436] loss: 0.6075745224952698\n",
      "[step: 437] loss: 0.6053095459938049\n",
      "[step: 438] loss: 0.6030460000038147\n",
      "[step: 439] loss: 0.6007890701293945\n",
      "[step: 440] loss: 0.5985315442085266\n",
      "[step: 441] loss: 0.5962762832641602\n",
      "[step: 442] loss: 0.5940271615982056\n",
      "[step: 443] loss: 0.5917801260948181\n",
      "[step: 444] loss: 0.58953857421875\n",
      "[step: 445] loss: 0.5873017311096191\n",
      "[step: 446] loss: 0.5850668549537659\n",
      "[step: 447] loss: 0.5828377604484558\n",
      "[step: 448] loss: 0.5806131958961487\n",
      "[step: 449] loss: 0.5783937573432922\n",
      "[step: 450] loss: 0.576180100440979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 451] loss: 0.5739704370498657\n",
      "[step: 452] loss: 0.5717666745185852\n",
      "[step: 453] loss: 0.5695687532424927\n",
      "[step: 454] loss: 0.5673761367797852\n",
      "[step: 455] loss: 0.5651897192001343\n",
      "[step: 456] loss: 0.5630075931549072\n",
      "[step: 457] loss: 0.5608311891555786\n",
      "[step: 458] loss: 0.5586600303649902\n",
      "[step: 459] loss: 0.556493878364563\n",
      "[step: 460] loss: 0.5543327331542969\n",
      "[step: 461] loss: 0.5521752238273621\n",
      "[step: 462] loss: 0.550021767616272\n",
      "[step: 463] loss: 0.5478715896606445\n",
      "[step: 464] loss: 0.545724630355835\n",
      "[step: 465] loss: 0.5435801148414612\n",
      "[step: 466] loss: 0.5414369702339172\n",
      "[step: 467] loss: 0.5392956137657166\n",
      "[step: 468] loss: 0.5371547341346741\n",
      "[step: 469] loss: 0.5350140333175659\n",
      "[step: 470] loss: 0.5328727960586548\n",
      "[step: 471] loss: 0.5307300686836243\n",
      "[step: 472] loss: 0.5285857915878296\n",
      "[step: 473] loss: 0.5264390110969543\n",
      "[step: 474] loss: 0.5242892503738403\n",
      "[step: 475] loss: 0.522136390209198\n",
      "[step: 476] loss: 0.5199794769287109\n",
      "[step: 477] loss: 0.5178182125091553\n",
      "[step: 478] loss: 0.5156521797180176\n",
      "[step: 479] loss: 0.5134809017181396\n",
      "[step: 480] loss: 0.5113042593002319\n",
      "[step: 481] loss: 0.5091218948364258\n",
      "[step: 482] loss: 0.5069332718849182\n",
      "[step: 483] loss: 0.5047383904457092\n",
      "[step: 484] loss: 0.5025368928909302\n",
      "[step: 485] loss: 0.5003283619880676\n",
      "[step: 486] loss: 0.4981130063533783\n",
      "[step: 487] loss: 0.49589017033576965\n",
      "[step: 488] loss: 0.4936597943305969\n",
      "[step: 489] loss: 0.49142149090766907\n",
      "[step: 490] loss: 0.48917534947395325\n",
      "[step: 491] loss: 0.4869202971458435\n",
      "[step: 492] loss: 0.48465701937675476\n",
      "[step: 493] loss: 0.4823848605155945\n",
      "[step: 494] loss: 0.4801032841205597\n",
      "[step: 495] loss: 0.47781243920326233\n",
      "[step: 496] loss: 0.47551122307777405\n",
      "[step: 497] loss: 0.4731999635696411\n",
      "[step: 498] loss: 0.4708781838417053\n",
      "[step: 499] loss: 0.4685456454753876\n",
      "RMSE: 0.01950150541961193, predict:[[0.19135691]\n",
      " [0.2085467 ]\n",
      " [0.22989178]\n",
      " [0.24053419]\n",
      " [0.24983485]\n",
      " [0.24812655]\n",
      " [0.24274518]\n",
      " [0.23369886]\n",
      " [0.20794255]\n",
      " [0.17442313]\n",
      " [0.14860252]\n",
      " [0.13613918]\n",
      " [0.13774417]\n",
      " [0.1410836 ]\n",
      " [0.13536285]\n",
      " [0.13711628]\n",
      " [0.14196394]\n",
      " [0.1579963 ]\n",
      " [0.17981538]\n",
      " [0.1974051 ]\n",
      " [0.20536372]\n",
      " [0.21561602]\n",
      " [0.22251342]\n",
      " [0.23123677]\n",
      " [0.24437137]\n",
      " [0.24428299]\n",
      " [0.23804165]\n",
      " [0.22598378]\n",
      " [0.22691624]\n",
      " [0.23597375]\n",
      " [0.2474265 ]\n",
      " [0.25415152]\n",
      " [0.24023347]\n",
      " [0.2147717 ]\n",
      " [0.18721582]\n",
      " [0.16680372]\n",
      " [0.15898383]\n",
      " [0.15926288]\n",
      " [0.16366264]\n",
      " [0.16817445]\n",
      " [0.1705747 ]\n",
      " [0.1743028 ]\n",
      " [0.1811613 ]\n",
      " [0.17847493]\n",
      " [0.17501357]\n",
      " [0.17414477]\n",
      " [0.17765221]\n",
      " [0.17777446]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build a stacked LSTM network\n",
    "def create_one_lstm_cell():\n",
    "    return tf.contrib.rnn.LSTMCell(lstm_size, state_is_tuple=True)\n",
    "\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell([create_one_lstm_cell() for _ in range(num_layers)], state_is_tuple=True\n",
    "                ) if num_layers > 1 else create_one_lstm_cell()\n",
    "\n",
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_size, activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    rmse_val = sess.run(rmse, feed_dict={\n",
    "                    targets: testY, predictions: test_predict})\n",
    "    print(\"RMSE: {}, predict:{}\".format(rmse_val, test_predict))\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(testY)\n",
    "    plt.plot(test_predict)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Standard Price\")\n",
    "    plt.show()\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, \"/tmp/model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before transpose, val.get_shape() = (batch_size, num_steps, lstm_size)\n",
    "# # After transpose, val.get_shape() = (num_steps, batch_size, lstm_size)\n",
    "# outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "# # last.get_shape() = (batch_size, lstm_size)\n",
    "# last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1, name=\"last_lstm_output\")\n",
    "\n",
    "# weight = tf.Variable(tf.truncated_normal([lstm_size, input_size]))\n",
    "# bias = tf.Variable(tf.constant(0.1, shape=[input_size]))\n",
    "# prediction = tf.matmul(last, weight) + bias\n",
    "\n",
    "    \n",
    "# loss = tf.reduce_mean(tf.square(prediction - targets))\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "# minimize = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
